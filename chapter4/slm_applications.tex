% -----------------------------------------------------------------------------
% 1) Move to a map of the UK 
% 2) show edge effect and epicenter changes
% 3) introduce the data-set in a formal capacity + define the threshold function
% 4) show how heterogeneity changes the problem i.e. discontinuities in the phase diagram
% -----------------------------------------------------------------------------

\chapter{Simple lattice model: applications (Re-work in progress)}
\label{chapter:SLM-applications}

This project is focused on tree disease in the United Kingdom. %
So far, the investigation has been limited to an abstraction on a homogeneous lattice. %
Therefore, in this chapter the simple lattice model will be projected onto the distribution of Oak canopy cover data given %
by \cite{hill.data}. %
This chapter will demonstrate how a more realistic model can be developed %
incorporating heterogeneity and how %
introducing a heterogeneous distribution of hosts constrains the model behaviour %
in a number of ways. %
This chapter is divided into two parts. %
First, the more complicated irregular boundary is considered and this changes the nature of pathogen%
 spread in the model. %
Secondly,  heterogeneity in the host distribution is examined along with the altered properties %
of disease transmission. %
Previously, it has been shown that heterogeneity strongly influences the  dynamical properties %
of a pathogen invasion \cite{madden1995plant}. %
Therefore, transitioning into a realistic domain informed by data-sets will significantly %
alter the  behaviour of the model.  %

In Chapter \ref{ch3:two-param-model} a host-unit is comprised of a single tree. %
Here, the scale is increased and host-units now represent as  $1\mathrm{km}^2$ patches of land \textemdash inline with the data reported by \cite{hill.data}. %

Lastly, the results of early-warning signals (EWS), investigated by \cite{OROZCOFUENTES201912}, will be extended. 
Extensions will include forming an alternate lattice configuration and a metric that permits clearer EWS detection. %
Additionally, EWS are generalised to a two-dimensional parameter-space of $\rho$ and $\beta$ from which follows the observation that it is easier to observe EWS through specific parameter combinations.


% These are notes, write these as prose (proper sentences ) please!
% \begin{itemize}
%     \item \textcolor{red}{introduce the notion of scale change}
%     \item \textcolor{red}{introduce data-set more thoroughly }
%     \item \textcolor{red}{allude to some of the problems of moving to heterogeneous data-set}
% \end{itemize}

\section{Early warning signals\textemdash detection and method}

Applications of early warning signals were investigated by \cite{OROZCOFUENTES201912} for forest management and ecosystems-services
\textemdash for a review on early 
warning signals and critical-slowing down in landscape ecology, see Section \ref{section:ews}. 
The work of \cite{OROZCOFUENTES201912} concentrated on a one dimensional parameter space of %
tree density $\rho$ over a square lattice. %
Statistically significant changes (or signals) in the moment-generating functions, %
that being variance, skew and auto-correlation, were calculated from the ensemble distributions of Figures \ref{fig:vel_eff_rad_metric}(b-d). %
Observations of these statistical measures can be used to preempt phase-transitions into the epidemic regime. %
This is useful information that could aid forest and plantation managers to maintain tree health. %

Here, we offer a small extension to some of the concepts presented by \cite{OROZCOFUENTES201912}. %
In particular, a new domain and metric is used that allows for clearer, more realistic early warning signals.  %
Additionally, analysis is generalised to two-dimensions in the parameter-space of $\rho$ and $\beta$. %
After introducing these alternative concepts, we discuss some of the problems and complexities encountered with ensemble-averaging. %

\subsection{Alternative early warning detection}

In order to detect an early warning signal, an assessment of  the temporal variability of the system is needed. %
The findings of \cite{OROZCOFUENTES201912} were gathered by first producing a distribution of \textit{mean} time-series velocities $\overline{v}(t)$, %
analogous to Figures \ref{fig:vel_eff_rad_metric}(b-d). %
The variance, skewness and autocorrelation were then calculated over these distributions. %
In this scheme, an early warning signal is detected from the \textit{variance of the mean} velocity i.e. $var\big\langle \overline{v}(t) \big\rangle $. %

When assessing alternative techniques for early warning detection, we found an early warning signal was more accurately %
detected with calculations based on the mean \textit{time-series variance} i.e. $var\big(v(t) \big)$. %
From the measure of time-series variance, repeated simulations generate an ensemble mean $\langle \overline{var}\big(v(t) \big)\rangle$. %
This slight variation in methods was found to yield a stronger signal in comparison to the original formulation. %

We proceed by detailing an ensemble-method that permits the capture of `in-simulation' variance. %

\subsection{Ensemble averaging method}

In order to properly analyse an ensemble of time-series variances, we require that the same %
number of observations are made within each ensemble. %
Otherwise, classification of an early warning signal might be confused and interpreted as %
a false positive\textemdash i.e. misjudged on account of statistical fluctuations and error. %
To ensure the number of observations are equal between all simulations, %
it is important to distinguish between a set of \textit{independent} simulations and the %
time-step observations which may differ between simulations. %

In general, any two independent simulations will not have the same number of time-steps, %
i.e. $|V_i^{\rho\beta}| \neq |V_j^{\rho\beta}|$. %
If this is not taken into account, comparisons between different ensembles will not be %
comparable because the variance calculated for short-lived simulations will be more error-prone %
than long-lived simulations. %
To remedy this, a fixed window of time-steps ($t_O\leq t \leq t_F$) is introduced. %
Provided the window length $t_F-t_O$ captures a sufficient number of time-steps, the effects %
of \textit{unlikely} large fluctuations in $V_i^{\rho\beta}$ are alleviated. Inside this window, %
the variance for all simulations will be calculated, Eq (\ref{eq:ews_eq}) is then slightly altered: %

\begin{equation}
\label{eq:ews_eq1}
    \big\langle \overline{var}(v^{\rho\beta}_{cm}) \big\rangle = \frac{1}{N}\sum\limits_{i=1}^{N} var(V_i^{\rho\beta}\Big|^{t_F}_{t_O})
\end{equation}

The precise choice of $t_O$ and $t_F$ is constrained by initial transience in the channel %
domain\textemdash analogously mentioned in the discussion of Figure \ref{fig:vel_eff_rad_metric}(a). %
Initial instability in the domain deserves some special consideration as it could distort %
calculations of the time-series variance. %
Figure \ref{fig:ews-primer}(c) reveals that transience occurs most for $t\in[0, 100]$, %
clearly demonstrated by increases in the blue time-series. %
The initial transience is less obvious for the blue and green time-series. %
As such, the first $100$ time-steps should not be included when calculating the variance. %
This means that all simulations that become extinct in less than $100$ time-steps are not %
included in the ensemble average. From these observations, the lower bound is valid for $t_O \geq 100$.%

Unfortunately, neglecting short-lived simulations $t<100$ introduces an additional complication. %
Namely, if we do not include these simulations, some ensembles $\mathcal{V}_{\rho\beta}$ %
(typically with low values of $\rho$ and $\beta$) will comprise less than $N$ measures of %
time-series variances. The ensemble mean, as calculated by Eq (\ref{eq:ews_eq}), will therefore %
be subject to more error which again could lead us to misclassify an early warning signal. %

An unbiased treatment of the ensemble thus requires i) the same number of time-steps in all %
simulations ii) the mitigation of initial instability iii) the same number of $N$ simulations %
are averaged for all points in phase-space. Combining all these requirements is clearly impossible %
for some points in parameter-space. Take the trivial example of $\rho=0$ and $\beta=0$, even %
as $N\rightarrow\infty$ not a single simulation will exist for $t\geq100$ steps and the %
variance remains undefined. For some fixed values of $\rho < \rho_c$ and $\beta<\beta_c$, %
the probability of all $N$ simulations surviving for longer than initial transience is zero. %

Fortunately, an early warning signal is only detectable immediately before and after the %
transition into an epidemic. If the \textit{mean} extinction time for these regions is %
above $t_F$, an early warning signal may be can be detected with confidence. %
Other regions in parameter-space well below-threshold are not important. %
So, a comparable treatment of ensembles can be accomplished provided that regions just %
below the point of epidemic-transition survive long enough to measure variance in the %
window $t \in [t_O, t_F]$. Should the value of $t_F$ be too large, a large proportion of %
simulations close, but below threshold, might not survive to give $N$ measures of variance. %

Given these concerns, a window was defined by setting the lower bound equal to the minimum %
value of $t_O=100$ and the upper bound to a value $t_F = 200$. %
These values were found to strike the best balance between: avoiding initial transience, %
ensuring that \textit{as many simulations as possible} on the verge of epidemic survive long %
enough to calculate variance and providing a sufficient window size. Using these conditions %
and the domain configuration of in Figure \ref{fig:ews-primer}(a), most simulations just below %
threshold (with some exceptions that are discussed below) were found to survive for longer %
than $200$ time-steps allowing for a multi-dimensional parameter-space analysis of early %
warning signals. %

\subsection{Cylindrical geometry\textemdash a change of domain}

The metric used by \cite{OROZCOFUENTES201912} to quantify early warning signals had the same form as Eq (\ref{eq:vel_eff_r}), albeit with a slight difference. %
The results included both the infected and removed ($N_{I+R}$), whereas Eq (\ref{eq:vel_eff_r}) %
was defined in terms of just the infected ($N_I$). %
Both metrics, based on the number of infected, are subject to geometrical effects as the wave %
spreads outwards and increases in radial extent. %
This can be seen by net increases in the velocity time-series for later times %
\footnote{See Figure 4d in \cite{OROZCOFUENTES201912}. Increase in the velocity metric are purely due to artifacts of geometry and metric definitions, in contrast to the wave of infected trees propagating through the domain at a faster rate.}

To mitigate any unwanted geometric effects, %JS explain
we use an alternate lattice configuration. %
Consider a rectangular domain of size $[L_x, L_y]$ where $L_x>L_y$ and $(x, y)$ represent dimensions %
of length and height respectively. This scenario is shown in Figure \ref{fig:ews-primer}(a). %
The initial conditions are changed such that the first column (denoted by $x_0$, taken as the origin) is infected. %
Additionally, boundary conditions are altered so disease propagates freely in the $+x$ and $\pm y$ directions. %
Thus, a cylindrical geometry is assumed with periodic boundary conditions in the $y$ direction and fixed boundary conditions in $x$. %
If an infected tree reaches the last column, denoted by $x_m$, simulations are terminated. %

A sufficiently narrow rectangular domain has the effect of collapsing the dimensionality of the travelling wave to somewhere between one and two dimensions. %
This is beneficial as geometrical effects are now reduced\footnote{Additionally, less space in computer memory is occupied, thus simulation time is reduced.} %
Percolation can be captured as before, but here defined between the $x_0$ and $x_m$ in the $x$ direction. %

A rigorous treatment of percolation theory would reveal different properties in the channel domain. % JS_Why write this and not be explicit?
Take for example, gradual reductions in the height of the domain, in the limit $L_x = 1$ a one-dimensional domain is realised and the percolation threshold increases to $\rho_c=1$. %
Therefore, universality classes will begin to look different as the height decreases. %


\subsection{Center of infection mass - a change of metric}

The rectangular domain, referred to as the \textit{`channel'}, now provides an advantageous setting to capture early warning signals. %
One may to define a new metric, useful for capturing the disease progression, is by considering the difference in mean distance between column $x_0$ obtained by infected trees per time-step:
\begin{equation}
   v_{cm}(t) = \frac{\sum^i x_i(t)}{N_I(t)} - \frac{\sum^i x_i(t-1)}{N_I(t-1)}
   \label{eq:COM}
\end{equation}

\begin{figure}
    \centering
    \includegraphics[scale=0.30]{chapter3/figures/figure10.pdf}
    \caption{(a) A channel domain of size $50\times350$ showing three time-steps of the model with parameters $\rho=0.65$ and $\beta=0.50$. The center of infectious mass is recorded for each time-step. (b) The center of mass time-series over the simulation. (c) The mean center of mass time-series (of $10^4$ repeats) for three variations in density and $\beta=0.50$. Time-series begin to decay around the mean simulation run-time.  The zoomed inset shows the ensemble averaged time-series for $t\in[100, 200]$ and reveals increases in error bars lower density parameters.}
    \label{fig:ews-primer}
\end{figure}

where $x_i(t)$ is the spatial location along the $x$ axis of the $ith$ infected tree at %
time $t$ and $N_I(t)$ is the total number of infected trees at time-step $t$. %
Comparing Eq (\ref{eq:COM}) with the Newtonian equation for center of mass: %
\begin{equation}
    x_{cm} = \frac{\sum^i x_i\times m_i}{\sum_i m_i}
\end{equation}
One can see the rate change in Eq (\ref{eq:COM}) can be considered as the `center-of-infection-mass' (COM) velocity %
with $m_i=1$ and $\sum^im_i= N_I$. %
This is easily implemented in Python, see Appendix \ref{a:slm_metrics}. %
The time-series of Figure \ref{fig:ews-primer}(a) is shown in Figure \ref{fig:ews-primer}(b) using $v_{cm}$. %
The COM time-series looks different to those shown previously in Figure \ref{fig:vel_eff_rad_metric}(a) allowing for the possibility of negative values. %

An ensemble average of the time-series, denoted by $\langle v_{cm}\rangle$ is illustrated in Figure \ref{fig:ews-primer}(c). %
Three different values of density were used and show  interesting properties: %
the mean time-series begins to systematically decay after the mean life-time of the simulation, %
the blue time-series shows a drastic decrease around $t \in [800, 900]$ when the pathogen %
reaches the boundary of the domain\textemdash illustrated in Figure \ref{fig:ews-primer}(a). %
The green time-series (being just above the threshold for percolation) decays gradually from %
the onset $t=0$ on account of a higher probability of extinction. %
A small number of long-lasting simulations $t>1000$ occurred in the green time-series and reflect criticalilty in the system. %

The inset of Figure \ref{fig:ews-primer}(c) shows the ensemble-averaged time-series between %
$t\in [100, 200]$ with the error measured for each time-step. Error bars, and therefore variance, %
is greatest for lower values of density, suggesting a more chaotic spread. %
In principle, if in-simulation variance such as this looks different before and %
after the epidemic regime is attained in parameter-space, an early warning signal could be detected. %

In general, a single simulation with parameters $\rho, \beta \in [0, 1]$ will last for $f$ time-steps. %
The metric-value at each step is defined Eq (\ref{eq:COM}) and can be described by the series, $v_{cm}^{t=1}, v_{cm}^{t=2},..., v_{cm}^{t=f} \in V^{\rho\beta}$. %
A set of independent time-series are generated by repeating $N$ simulations. %
A single point in the phase-space diagram is then described by $V_1^{\rho\beta}, V_2^{\rho \beta},..., V_N^{\rho\beta} \in \{\mathcal{V}_{\rho\beta}\}$, %
where $V_i^{\rho\beta}$ represents an arbitrary simulation time-series. %
Using this notation, an early warning signal is detected by calculating the mean time-series variance, %
defined by:
\begin{equation}
\label{eq:ews_eq}
    \big\langle \overline{var}(v^{\rho\beta}_{cm}) \big\rangle = \frac{1}{N}\sum\limits_{i=1}^{N} var(V_i^{\rho\beta})
\end{equation}


\section{Early warning signal results}
\label{section:ews_slm}

Figure \ref{fig:ews-results} shows the mean time-series variance between $100\leq t \leq 200$. %
The value of variance is shown in the colour bar from white to black. %
The lower and upper red lines highlight regions in parameter space for which the %
probability of percolation is $Pr(\rho, \beta)=0.05$ and $Pr(\rho, \beta)=0.95$ respectively, %
those being the  critical regions in parameter-space that support an epidemic. %
The precise value of variance is not important, but crucially, a rise in time-series variance %
can be seen before the onset of epidemic. %
This is in agreement with the results found by \cite{OROZCOFUENTES201912}. %
%% with the benefit of being more adaptable to real-life time-series observations of tree diseases.

Assessing early warnings over a two-dimensional parameter-space reveals that some values %
of $\rho, \beta$ preempt the epidemic by a larger margin\textemdash indicated by the red %
arrows in Figure \ref{fig:ews-results}. Specifically this occurs for a lower infectivity %
($\beta<0.40$) and higher density. What aspect of the SLM gives rise to these differences %
behaviour when detecting an early warning signal? %

 \begin{figure}
    \centering
    \includegraphics[scale=0.45]{chapter3/figures/figure11.pdf}
    \caption{The ensemble-averaged variance of $v_{cm}(t)$ over a two dimensional parameter sweep of $\rho$ and $\beta$. Red contours show the lower and upper bound of percolation (i.e. between $5\%$ and $95\%$ probability). 
     The epidemic regime is preempted by increases in variance more clearly for certain parameter values, %
     indicated by the arrows.}
    \label{fig:ews-results} 
\end{figure}

The asymmetry in early warning detection can be understood through the following thought-experiment: %
first, consider a high value of $\beta$ and density just below criticality $\rho\lesssim\rho_c$. %
In this case, the rate of disease progression is higher on account of $\beta$ and all hosts %
that are susceptible will become infected quickly. %
However, disease spread will soon come to a halt due to insufficient number ofhosts. %
An aggressive pathogen that has a low density of hosts will therefore propagate rapidly, %
have short extinction times and give rise to a more chaotic metric signature. %
Hence, the smallest arrow in Figure \ref{fig:ews-results} points toward a region where the %
variance spike is greatest and has no trace below the lowest bound of $5\%$ percolation probability. %

Conversely, a pathogen that has a low infectivity but an abundance of hosts will spread %
slowly but predictably through the domain. The pathogen is thus more likely to spread for a longer time before becoming extinct. In this scenario extinction times are long enough to process an early warning signal which precedes the epidemic by a larger margin, indicated by the large arrow(s) in Figure \ref{fig:ews-primer}. Here, variance can be seen to preempt the transition to a larger degree, however, the variance spike is not as strong.
 
These observations and Figure \ref{fig:ews-primer} point toward a distinction between an %
aggressive pathogen just below $\rho_c$ and a less aggressive pathogen well beyond $\rho_c$. %


\section{Modelling with realistic geometries}

% JS_Another thought experiment as in the previous chapter? - This is lazy just consider this properly and formally.

Consider a single source of infestation located at the center of a regular square domain. %
The number of the infected-dead trees which result from an outbreak is determined. %
Then the boundary of the square domain is randomly deformed such that a complicated irregular %
shape is realised and  the epicenter is arbitrarily re-positioned  to a different position. %
From this, it is clear to see that the total number of infected-removed trees is going to be different from the regular-isotropic scenario. %
Therefore, we assume \textit{a priori} that a complicated geometry can alter both the threshold and how the dynamic behaviour of the disease progression is defined. %

Using the same $SIR$ compartments and model dynamics to those presented in Chapter \ref{chapter:SLM}, %
we move onto a map of Great Britain. As a first step, only the coastline of Great Britain will be explored. %
That is, the introduction of a complicated geometrical boundary or edge. %
Figure \ref{fig:uk-spread-primer} shows an outline of Great Britain (GB) filled with a random homogeneous distribution of land `patches' at resolution $1\mathrm{km^2}$. %
Green represents susceptible patches and black represents insusceptible\textemdash as explained in the previous Chapter for trees a unit hosts. %

It is clear that edge effects will reduce the probability of an epidemic when the source %
of infection is at the coast or close to the boarder of an island such as GB. %
Depending on the level of geographical %
regularity, the local fractal dimension of the coastline will vary. %
The more irregular the portion of coastline, the closer the fractal dimension will approach $2$. %
Whereas, a perfectly straight coastline will have a fractal dimension of $1$. An example of %
how edge effects may alter the spread of disease is shown in the inset of Figure \ref{fig:uk-spread-primer}. %
An epicenter just below the Humber estuary is thought to pose less risk on account of the discontinuity between landmass. %

If an epicenter is located on the boundary of an irregular coastline, pathogen-impedance %
will be high and the risk of epidemic reduced. If, on the other hand, an epicenter was located inland, %
the effects of an irregular coastline become negligible. %

To study  edge effects of the coastline and map-geometry, each lattice site $(i, j)$ inside %
the landmass (denoted by $\in \mathcal{L}_{GB}$) is taken as a potential epicenter. %

A simulation can then iterate through each lattice point $(i,j)$ where the infection will be %
allowed to evolve through the domain and the number of removed patches will be recorded. %
A measure of the scale of epidemic through each epicenter can be summarised by a metric of the form: %
\begin{equation}
\label{eq:epi_impact}
    \chi=\frac{|R|}{S_0}
\end{equation}
where $|R|$ is the number of patches in the removed state and $S_0$ is the number of susceptible %
patches at time $T=0$. Here, $\chi$ represents a naive indicator of \textit{tree-mortality} %
and by extension `\textit{epidemic-impact}'. The measure $\chi$ will be refereed to as mortality %
ratio from now on. %

\begin{figure}
    \centering
    \includegraphics[scale=0.3]{chapter4/figures/figure1.pdf}
    \caption{The simple lattice model spreading on a map of GB. Lattice geometry and epicenter %
    location are non-trivial aspects likely to influence the spread of disease. The zoomed inset %
    shows an example of the Humber estuary preceding an infectious wave-front. }
    \label{fig:uk-spread-primer}
\end{figure}

% Introduce simulation run-time and mortality. Show epicenter variations
\begin{figure}
    \centering
    \includegraphics[scale=0.32]{chapter4/figures/figure2.pdf}
    \caption{Each pixel in the domain is treated as an epicenter and averaged over an ensemble. %
    Color shows the mortality ratio $\chi$ for each spatial location and demonstrates edge effects %
    in a complicated landscape.}
    \label{fig:uk-spatial-risk}
\end{figure}

Given the system stochasticity, it is necessary to repeat simulations for each epicenter %
and calculate $\overline{\chi}$. Iterating over the whole of the GB in this way allows us 
to visualise the spatial-susceptibility of the pathogen $\beta$. %
The value of spatial-susceptibility depends on both $\rho$ and $\beta$ and forms a primitive %
notion of risk within the toy-model. %

Figure \ref{fig:uk-spatial-risk} shows the result of ensemble averaging $\chi$ for each %
patch of land\footnote{Ensemble averaging each patch of land is computationally intensive. %
To account for this domain shown in \ref{fig:uk-spread-primer} was coarse-grained to a resolution of $5\mathrm{km^2}$. %
Simulations were conducted on the Leeds high-performance computing facility, the ARC-HPC system. %
The simulations shown in Figure \ref{fig:uk-spatial-risk} were ensemble-averaged using a task %
array and had a run-time of two hours (Repeated once per core, using $25$ cores).} %

The SLM assumed parameter values of $\rho=0.65$ and $\beta=0.25$ (just above threshold in a $2D$ square lattice). %
As expected, regions close to the edge are unlikely to result in a large epidemic. %
The narrow width across the Anglo-Scottish boarder reduces the mortality. %
Centralised regions show a roughly constant susceptibility. %

The method presented to assess spatial susceptibility, combining ensemble-averaging and %
spatially iterations for distinct land-points, will be frequented throughout the thesis. %

\section{Introducing realistic host data}

So far, this work has concentrated on a random homogeneous distribution of hosts. %
We now consider what changes occur for more realistic heterogeneous distributions. %
In ecology, collecting high quality data is time consuming and expensive. %
As remarked in Section \ref{chapter2:plant-ecologoy}, sampling a species to generate host %
data over an entire country is unfeasible. %
To account for this, an inferred data-set of common Oak (\textit{Quercus robur}) is used, %
as reported by \cite{hill.data}. %
This will couple the toy-model to a heterogeneous data-set and allow us to explore some %
fundamentally different properties. %
 
The distribution of Oak data is shown in Figure \ref{fig:uk-oak-l.hill}(a) along with its 
probability density function in  Figure \ref{fig:uk-oak-l.hill}(b). %
The units are hectares of canopy cover per kilometer squared of land, $\mathrm{ha/km^{2}}$. %
This is a convenient choice given $\mathrm{1\ ha = 0.01\ km^2}$. Each measure of abundance %
value can therefore be seen as a `percentage' of cover per land-point. %
The Abundance canopy cover, denoted by $\rho$, is shown in \ref{fig:uk-oak-l.hill}(a) as colour. %
As we can see, the spatial map now displays strong irregularities and host heterogeneity is visible. %

The probability density function, $f(\rho)$, is shown in Figure \ref{fig:uk-oak-l.hill}(b) and %
reveals that most land patches occupy a lower canopy cover values. %
The distribution had a small number ($\sim 5\%$) of outlying host abundance values%
 $10<\rho<35\ \mathrm{ha/km^2}$ which skewed the distribution. %
 These were reduced to $10\mathrm{ha/km^2}$ thus capping the highest value of $10\%$ canopy cover. %
 
The Oak data-source presents a problem when one recounts the SLM host-densities lay in the %
interval $\in [0, 1]$. Additionally, for each value of density, the SLM  assumed a binary %
valued domain with susceptible and empty lattice points. %
This is contrary to Figure \ref{fig:uk-oak-l.hill}. %

\begin{figure}
    \centering
    \includegraphics[scale=0.32]{chapter4/figures/figure3.pdf}
    \caption{(a) The modelled abundance distribution of common oak (\textit{Quercus robur}), inferred by \cite{hill.data}. The each pixel holds a predicted value of abundance having units hectares of canopy cover per kilometer squared of land. (b) The probability density function of abundance $f(\rho)$. The zoomed inset illustrates the process of generating threshold function $\phi$.}
    \label{fig:uk-oak-l.hill}
\end{figure}

In order to account for this, a threshold function $\phi(\rho)$, is introduced and defined by:
\begin{equation*}
  \phi(\rho) =
  \begin{cases}
    1 & \rho_{i,j}\geq\rho \\
    0 & \rho_{i,j}<\rho
  \end{cases}
\end{equation*}
for each continuous value of abundance, $\rho\in[0, 10]\ \mathrm{ha/km^{2}}$, the function %
 $\phi$ converts a patch of land $(i,j)$ into a binary value of one if it is greater than or %
 equal to $\rho$, otherwise zero. %
 This generates a binary-valued domain with susceptible $S$ when $\rho_{i,j} > \rho$ and %
 insusceptible $\emptyset$ when $\rho_{i,j} < \rho$. This idea is captured on the inset of %
 Figure \ref{fig:uk-oak-l.hill}(b), the vertical black line is an arbitrary threshold of %
 density $\rho$, where all canopy cover values less than $\rho$ are taken as insusceptible %
 with numerical value $0$. Whereas, all patches of canopy cover in the data equal to or greater %
 than $\rho$ are taken as susceptible and take the value $1$. In this picture, susceptible %
 land-patches have enough Oak trees to support the survival, growth and spread of disease. %
 Patches of land below the abundance threshold are presumed insusceptible and have an insufficient %
 number of hosts to survive and reproduce. %

In chapter \ref{chapter:SLM}, a distribution of hosts were easily characterised with $\rho$. %
Now however, heterogeneity in the data prevents a simple description of density. %
To overcome this one can define an \textit{`effective'} domain density, denoted by $\rho^*$,  by considering the percentage of susceptible land inside the domain:
\begin{equation}
    \label{eq:rho_eff}
  \rho^{*} = \frac{\sum^{i, j} ( \rho_{i,j} \geq \rho )}{|\mathcal{L}_{GB}|}
\end{equation}
where $\mathcal{L}_{GB}$ represents host distribution over Great Britain. %
 The terms $\sum^{i, j} (\rho_{i,j} \geq \rho)$ and $|\mathcal{L}_{GB}|$ therefore represent %
 the total number of susceptible patches and total landmass respectively. %

Given an increase in the susceptibility threshold $\rho$, the %
 effective density $\rho^*$ decreases. % 
However, a  decrease in the threshold $\rho$ increases $\rho^*$ as more patches become susceptible. %
The effective density $\rho^{*}$ therefore presents a convenient, although primitive, proxy %
for the density of host occupation over a heterogeneous distribution. %

\subsection{Epidemics through heterogeneous landscapes}
\begin{figure}
    \centering
    \includegraphics[scale=0.490]{chapter4/figures/figure4.pdf}
    \caption{The simple lattice model running on a binary-valued Oak domain with infectivity $\beta=0.25$ for three variations of effective density $\rho^*$.}
    \label{fig:ch4_uk_spread}
\end{figure}

Using the effective density ($\rho^{*}$), defined in Eq (\ref{eq:rho_eff}), a set of %
binary-valued domains can be initialised from an arbitrarily chosen thresholds of abundance %
canopy cover ($\rho$). %
Figure \ref{fig:ch4_uk_spread} shows the domain that results from three variations of effective density $\rho^{*} \in [0.40, 0.50, 0.60]$, the corresponding thresholds of abundance canopy cover shown below. %
The SLM is projected onto the map as allowed to evolve indefinitely until pathogen-extinction. %
Figure \ref{fig:ch4_uk_spread} shows slices through four time-steps. %

From panels (a) (e) and (i), the differences in the domain density are apparent\textemdash larger values of abundance-threshold produce lower density maps. %
For all effective densities, the initial source of infection was planted in the south where canopy cover is most dense. %
The pathogen then initially progresses through the domain, $0<t<250$, unimpeded by a low number of insusceptible regions. %
Panels (f) and (j) show the how the process volved in a uniform manner showing to density is above the threshold for propagation. %
At $t=250$, panel (b) shows pathogen progression inhibited by a barrier of insusceptible patches. %


Previously, density was uniform in all directions. %
Now however, heterogeneity unevenly distributes susceptible patches of land. %
This has implications for the pathogens evolution and spread. %
As discussed in Chapter \ref{chapter:SLM}, the critical density for propagation is $\rho_c\sim 0.60$ and therefore propagation on the heterogeneous domain will result if the`\textit{local}' density satisfies $\rho>\rho_c$. %
This is true for Figure \ref{fig:ch4_uk_spread} around the initial source of infection. %
In panels (c) and (d) we can identify a centralised region in Great Britain, approximately extending from Oxford to Buckinghamshire where density is below the threshold. 
This results in pathogen-extinction just beyond $t=750$. %

Figure \ref{fig:ch4_uk_spread} hints towards clusters in the domain through which local densities are large enough to support an epidemic. %
For a domain of arbitrary density, consider two distinct clusters where local densities are above threshold, $C_1$ and $C_2$, with two lattice sites $p\in C_1$ and $q\in C_2$. %
Then $p \neq q$. However, small increases in $\rho^{*}$ have the potential to radically change the scale of epidemic impact by opening up a small number of susceptible patches such that $p=q$. %
This motivates an understanding of the relationship between $\rho^*$, $\beta$ and the final epidemic size. %
This can be summarised by the mortality ratio $\chi$, as defined in Eq (\ref{eq:epi_impact}). %

In this domain-configuration, percolation is ill-defined because there is now no notion of spatial extent between boarders as previously defined for the square lattice. %
Small changes in the epicenter and initial conditions can also can have large impacts on the progression of disease. %
Additionally, more noise and stochasticity is introduced to the time-series showing disease progression, which makes velocity-based metrics such as Eq (\ref{eq:vel_eff_r}) harder to use. %
In the heterogeneous domain, the most intuitive and informative metric to employ is the mortality ratio $\chi$. %

For this reason, it makes sense to investigate epidemic-impact as a function of epicenter-location. %
To do this, we employ the ensemble-averaging method shown in Figure \ref{fig:uk-spatial-risk} for different values of effective density and infectivity. %

\begin{figure}
    \centering
    \includegraphics[scale=0.4]{chapter4/figures/figure5.pdf}
    \caption{Spatial phase showing ensemble statistics over the oak data-set for three variations of density threshold $\phi(\rho): \rho \in [0.37, 0.43, 0.50]$ and fixed infectivity $\beta=0.25$. (a-c) The ensemble mean of mortality ratio $\chi$ measured for each pixel epicenter. The dotted red circle in Fig (a) shows two neighbouring susceptible regions. (d-f) Ensemble variance over $\chi$. The dotted shape in (d) highlights an unstable region of high variance and uncertainty separating two susceptible areas of the population in Fig (a).}
    \label{fig:oak-spatial-ensemble}
\end{figure}

The spatially-iterated and ensemble-averaged method is applied to the Oak data-set, shown in Figure \ref{fig:oak-spatial-ensemble}. %
Panels (a-c) show the mortality ratio $\big\langle \overline{\chi} \big\rangle$ indicated by the colour bar for three different effective densities (conveniently chosen for the purposes of demonstration). %
For a given epicenter, variations of the epidemic-scale were seen between successive simulations. %
Thus, the bottom row (d-f), show the variance for each epicenter's ensemble, $\langle \chi_{i,j} \rangle$. %

As expected, increases in the effective density $\rho^*$ yield a higher epidemic-impact, as shown by the magnitude of successive colour bars % JS_colours represent what scale?
and expansive growth of susceptible clusters\textemdash shown in yellow. %
The most notable feature in panels (a-d) is that the  emergence is from a centrally-located cluster. %
Spatial locations within the solid yellow region are all connected via Von Neumann neighbourhoods (see Chapter \ref{chapter:SLM}) and the mortality is approximately independent of epicenter. %
In panel (a), the spatial locations encircled in dashed red, highlight a region of instability which appears to separate two susceptible clusters. %

The mortality ratio was observed to fluctuate between simulations, this is captured by variance in panels (d-f). %
Panel (c), highlights the variance in epidemic outcome inside the region of instability of panel (a). %
Panels (e) and (f) are similar, both showing variance only at the edges of one centrally located susceptible region. %
Plotting spatial variance captures epidemic uncertainty in the toy-model. %

Figure \ref{fig:oak-spatial-ensemble} fails to display any information about how far an epidemic is likely to propagate. %
This could be captured by the correlation function, see Section \ref{section:universality}. %
An alternative simplified representation can be captured by ensemble-averaging the maximum distance reached by the pathogen, %
shown in Appendix \ref{a:slm_heterogeneous}. %
In general, there are a variety of metrics that could be used to capture various aspects of an epidemic. %
Table \ref{tab:metrics} shows all metrics that were considered along with the information they provided. %

\begin{table}[h!]
  \begin{center}
    \begin{tabular}{l|c|c|r} % <-- Alignments: 1st column left, 2nd middle and 3rd right, with vertical lines in between
    \hline
      \textbf{Metric} & \textbf{Notation} & \textbf{Domain type} & \textbf{Information captured}\\
      \hline
      Percolation & $Pr(\rho,..)$ & Simple & Probability of epidemic \\
      Time & $t$ & Simple and GB-based & Time-scale of epidemic  \\
      Max distance & $d_{max}$ & Simple and GB-based & Spatial scale of epidemic\\
      Mean distance & $d_{av}$ & Simple and GB-based & Spatial scale of epidemic\\
      Median distance & $d_{med}$ & Simple and GB-based & Spatial scale of epidemic\\
      Mortality ratio & $\chi$ & Simple and GB-based & Scale of epidemic\\
      Radial velocity & $v(t)$ & Simple and GB-based & Rate of disease progression \\
      $COM$ velocity & $v_{CM}(t)$ & Simple and GB-based & Rate of disease progression\\
    \hline
    \end{tabular}
    \caption{A summary of applicable metrics to a given domain along with their uses.}
    \label{tab:metrics}
  \end{center}
\end{table}

\subsection{Heterogeneous phase diagram}

\begin{figure}
    \centering
    \includegraphics[scale=0.32]{chapter4/figures/figure6.pdf}
    \caption{The ensemble-averaged epidemic phase-space behaviour over a map of Great British Oak. Simulations were initialised from a single epicenter, shown in red. (a) The mortality ratio $\chi$, is shown over a two dimensional parameter space of $\rho^*$  and $\beta$. (b) The mortality ratio is found over $\rho^{*}$ for different values of infectivity (c) The mortality ratio is found over infectivity $\beta$ for different values of effective density $\rho^{*}$.}
    \label{fig:heterogeneous-phase-space}
\end{figure}

% JS_ This is an arrogant statement because it suggests you are being lazy, refusing to argue  what insight an Analytical approach reveals
 It is both computationally intractable, and superfluous, to work out the phase-plane diagram for every potential source of infection in the domain. %
 As such, only a single epicenter was considered\textemdash if required % JS_ under what circumstances would it be required? What if your Examiners' find a flaw and and argue you are missing something obvious?
this could easily be extended to a small number of different epicenters. %
Figure \ref{fig:heterogeneous-phase-space} shows the ensemble-averaged epidemic phase space of the SLM when projected onto the heterogeneous map of Great British Oak canopy data. %
The Parameter sweeps from $\rho^{*}$ and $\beta$ both were considered. %
% JS_ so now you are considering  phase-space
The phase-space behaviour demonstrates multiple discontinuities and sharp increases in $\chi$ for certain combinations of $\rho^{*}$ and $\beta$. %
This occurs in stark contrast to the SLM phase-diagram for a random homogeneous domain. %
Figure \ref{fig:heterogeneous-phase-space}(a) reveals a large asymmetry between $\rho^*$ and $\beta$ as more discontinuities appear when $\rho^*$ is increased. %
This behaviour is highlighted in Figure \ref{fig:heterogeneous-phase-space}(b) as slices through the parameter space of $\beta$ are plotted over a one-dimensional parameter space of $\rho^*$. %

Figure \ref{fig:heterogeneous-phase-space}(c) details how variations of $\rho^*$ effect the model behaviour through $\beta$-space. %
A minimum infectivity of $\beta\sim0.10$ can be seen, below which no propagation is observed. %
This is identical behaviour to the SLM evolution on a uniform domain. %
Increases in $\beta$ incur fewer discontinuities compared to increases in $\rho^*$, as evidenced by smoother curves. %

The mortality ratio is independent of infectivity beyond $0.30 \lessapprox \beta$. %
This can be understood as follows: consider a domain with fixed density $\rho^*$ and $\beta=0.30$. %
The probability of a susceptible patch remaining susceptible when it encounters an infected neighbour is given by Eq (\ref{eq:pr_s_s}) as $Pr(S \rightarrow S) = (1 - 0.30)^{10} = 0.03$. %
Thus, on average the pathogen transmits successfully to susceptible neighbours with probability $Pr=0.97$. %
If the epicenter happened to belong to a cluster of size $100$, thus on average just three patches remain susceptible. %
In this case therefore, most patches in the cluster become infected and further increases in $\beta$ do not effect the % 
outcome\footnote{Increasing the infectivity to $\beta=0.40$ yields a $Pr(S \rightarrow S) = 0.006$, this would lead to negligible changes in the final epidemic size\textemdash however, the rate of progression would be faster.} of $\chi$. %
For $0.30 \lessapprox  \beta$, only increases to the domain density has the potential to raise the final epidemic size, %
this is indicated by the increases in the height of the curves in Figure \ref{fig:heterogeneous-phase-space}(c). %


\section{Chapter summary}

% Having established the SLM from first principles, the initial discussion of early warning %
% signals conducted by \cite{OROZCOFUENTES201912} was revisited using an alternate framework. %
% % 
% We used the \textit{mean} time-series variance, opposed to the variance of the \textit{mean} %
% time-series, a \textit{channel} domain with cylindrical boundary conditions and a metric that %
% traced the center of infectious-mass over time. From this, we proceeded to capture early warning %
% signals over a two dimensional parameter space whilst mitigating any unwanted geometrical effects. %
% % JS_can you rewrite and explain this more carefully ?

% When %setting up? 
% defining the early warning framework, a detailed description of the ensemble-averaging process %
% was given that permitted an unbiased treatment of simulations. %
% In this way, early warnings %
% were detected prior to the epidemic regime. Interestingly, asymmetries % JS_define these properly
% in the detection of early %
%  signals lead to some insightful observations about the model. %
%  % JS_be clear what is insighful!
%  Differences between a high $\beta$ and low $\rho$, were observed when compared against a low $\beta$ %
%  and high $\rho$ regime. For a high $\beta$ and low $\rho$ regime, early warning signals were detected %
%  further away from the epidemic regime. % JS_ explain further
%  In contrast, early warning signals for a low $\beta$ and high $\rho$ regime were only %
%  observable immediately before epidemic transition, although the variance spike was larger. %

% From these findings we may conjecture how it would be easier or harder to detect and prevent %
% either: a pathogen with infectivity on the verge of epidemic, or a region of hosts just below %
% the critical density. % JS_How dow these comment help you interpret other research?
% This could apply to a variety of systems in which environmental factors act to tip the pathogen %
% spread over the threshold for epidemic. % % JS_Can you explain what they are?

% Problematically however, the spread of disease through real systems cannot be ensemble averaged. %
% It therefore remains a speculative matter to consider how applicable this framework could be to %
% real landscapes and pathological systems. Early warning signals would be hard to resolve accurately in %
% practice due to various factors, including the cryptic nature of infestations, %
% long-ranged dispersal and more generally an insufficient knowledge of infected symptomatic hosts. %
% This re-investigation thus remains abstract and more work would need to be conducted before %
% accurate results can be established. %

In this chapter, the SLM operating on a realistic heterogeneous Oak tree canopy data has been considered as source of abundance. %
The units given were hectares of canopy cover per kilometer-squared $\mathrm{ha/km^2}$. %
The data source, given by \cite{hill.data}, was continuous and therefore incompatible with SLM %
when taken at face-value. % 
To account for this, we introduced an effective density parameter $\rho^*$ predicated on an %
arbitrarily chosen threshold value $\rho\ \mathrm{ha/km^2}$\textemdash defined in Eq (\ref{eq:rho_eff}). %
Where the abundance threshold $\rho$ represents a percentage of cover and therefore can be likened to the SLM density-parameter. %

At this point in the investigation, introducing an additional parameter $\rho^*$ is undesirable. %
In practice, ascertaining the threshold value $\rho$ for real host-pathogen interactions would add to the complexity and non-trivial to parse with the current toy-model. %
There were a few options to pre-possess the data that could have mitigated the introducing of an arbitrarily chosen threshold. %
An alternative we did not explore, is to consider initialising a random homogeneous square lattice inside the pixel of the canopy cover data. %
Doing so would be trivial to implement as abundance represents a percentage cover per unit of landmass, therefore reformulating the domain would simply involve multiplying the data by a factor $0.01$. %

Recasting the abundance data into a series of random-homogeneous domains exposes problems. %
Firstly, initialising a square lattice inside each pixel would incur a significant computational cost. %
Secondly, and most crucially, considering the numerical value of highest abundance patch we considered, $10\mathrm{ha/km^2}$ would translate into an SLM lattice density of just $0.10$, which  is far below the threshold $\rho_c \sim 0.60$ we computed in Chapter \ref{chapter:SLM}.%
Simply put, the mean distance between trees is too far and would not support simplified the NN interactions we have considered so far. 

Combining the SLM with the realistic data-source is a essential exercise as it revealed the SLM is the wrong model when considering large, realistic landscapes where the mean density (i.e. averaged over $1km^2$) is far below the threshold for propagation. %
This is not to say SLM would be useful for dense pockets of forest, both commercial plantations and natural, germane to small-scales. %
However, as we are motivated here by understanding large epidemics that spread over national-scales, so a change to the model must be made. 

To account for the low density of trees when smoothed over the landscape, we will now move towards a non-local model of spread describing pathogen dispersal. %
In this paradigm, transmission between trees can occur over larger length-scales and permit the spread over lower tree-densities. %
This is more reflective with the spread observed in Nature and has the desired effect of making the abundance threshold $\rho$ redundant. %
Such a scenario  allows the model to be directly informed by a realistic data-source of canopy coverage.
\newpage
